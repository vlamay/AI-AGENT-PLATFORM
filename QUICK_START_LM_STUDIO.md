# ‚ö° –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç —Å LM Studio

## üéØ –£ –≤–∞—Å —É–∂–µ –µ—Å—Ç—å LM Studio!

**–°—Ç–∞—Ç—É—Å**: ‚úÖ LM Studio –∑–∞–ø—É—â–µ–Ω  
**–ß—Ç–æ –Ω—É–∂–Ω–æ**: –í–∫–ª—é—á–∏—Ç—å API —Å–µ—Ä–≤–µ—Ä

---

## üìã 3 –ø—Ä–æ—Å—Ç—ã—Ö —à–∞–≥–∞

### –®–∞–≥ 1: –ó–∞–ø—É—Å—Ç–∏—Ç–µ Local Server –≤ LM Studio

1. –û—Ç–∫—Ä–æ–π—Ç–µ LM Studio (—É–∂–µ –∑–∞–ø—É—â–µ–Ω)
2. –í –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ –Ω–∞–π–¥–∏—Ç–µ **"Local Server"**
3. –ù–∞–∂–º–∏—Ç–µ **"Start Server"**
4. –í—ã–±–µ—Ä–∏—Ç–µ –ø–æ—Ä—Ç (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 1234)
5. –ù–∞–∂–º–∏—Ç–µ **"Start"**

**–ì–æ—Ç–æ–≤–æ!** LM Studio API —Ç–µ–ø–µ—Ä—å —Å–ª—É—à–∞–µ—Ç –Ω–∞ –ø–æ—Ä—Ç—É 1234.

---

### –®–∞–≥ 2: –ü—Ä–æ–≤–µ—Ä—å—Ç–µ API

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
curl http://localhost:1234/v1/models

# –î–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –≤ JSON
```

–ï—Å–ª–∏ –≤–∏–¥–∏—Ç–µ —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π ‚Üí ‚úÖ API —Ä–∞–±–æ—Ç–∞–µ—Ç!

---

### –®–∞–≥ 3: –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ

```bash
# –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
curl -X POST http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "local-model",
    "messages": [{"role": "user", "content": "Say hello!"}],
    "temperature": 0.7
  }'
```

---

## üîÑ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ø—Ä–æ–µ–∫—Ç–æ–º

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ n8n

–í n8n –¥–æ–±–∞–≤—å—Ç–µ HTTP Request node:

**URL**: `http://localhost:1234/v1/chat/completions`

**Method**: POST

**Body** (JSON):
```json
{
  "model": "local-model",
  "messages": [{"role": "user", "content": "{{ $json.body.prompt }}"}],
  "temperature": 0.7
}
```

---

## üöÄ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ LM Studio

‚úÖ **–ì—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å** - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ UI  
‚úÖ **–õ–µ–≥–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π** - –∫–ª–∏–∫ –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏  
‚úÖ **OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API** - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç  
‚úÖ **CUDA –ø–æ–¥–¥–µ—Ä–∂–∫–∞** - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç NVIDIA GPU  
‚úÖ **Switching –º–æ–¥–µ–ª–µ–π** - –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –æ–¥–Ω–æ–π –∫–Ω–æ–ø–∫–æ–π  

---

## üìä LM Studio vs Ollama

| Task | LM Studio | Ollama |
|------|-----------|--------|
| –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏ | ‚úÖ GUI | ‚ùå CLI |
| API –¥–ª—è –∫–æ–¥–∞ | ‚úÖ –î–∞ | ‚úÖ –î–∞ |
| Production deploy | ‚ö†Ô∏è –ù—É–∂–µ–Ω GUI | ‚úÖ Docker |
| –£–¥–æ–±—Å—Ç–≤–æ –¥–ª—è dev | ‚úÖ –û—Ç–ª–∏—á–Ω–æ | ‚ö†Ô∏è –°—Ä–µ–¥–Ω–µ |

---

## üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è

**–î–ª—è –≤–∞—à–µ–≥–æ —Å–ª—É—á–∞—è (—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ ASUS TUF laptop):**

‚úÖ **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ LM Studio** –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π LLM  
‚úÖ **–î–µ—Ä–∂–∏—Ç–µ Ollama** –∫–∞–∫ backup (—É–∂–µ –∑–∞–ø—É—â–µ–Ω)  
‚úÖ **–ü–µ—Ä–µ–∫–ª—é—á–∞–π—Ç–µ—Å—å** –º–µ–∂–¥—É –Ω–∏–º–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∑–∞–¥–∞—á–∏  

**–ü—Ä–∏–º–µ—Ä:**
- **Dev/–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: LM Studio (UI —É–¥–æ–±–µ–Ω)
- **Production**: Ollama (Docker deployment)

---

## üîó –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏

**LM Studio Docs**: https://lmstudio.ai/docs  
**API Reference**: http://localhost:1234/docs (–ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞)

---

**–ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä—å —É –≤–∞—Å —Ä–∞–±–æ—Ç–∞—é—Ç –æ–±–∞: LM Studio + Ollama** üéâ

